{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "여러분은 파이썬을 통해 설문조사 문항의 응답내역을 분석하게 되었습니다. 문항별 응답내용에는 하나의 응답만 할 수 있는 single choice 문제와 여러 응답을 선택할 수 있는 multiple choice 문제가 있습니다. 2개를 구분하기 위해 single choice 문항 번호에 \"_\"를 표기하지 않기로 했습니다.\n",
    "\n",
    "문항별 응답내역이 'question'에 담겨 있을 때, 조건문과 반복문을 사용하여 아래와 같은 결과가 출력되도록 코드를 작성해보세요.\n",
    "\n",
    "🔽 출력 예시\n",
    "\n",
    "```\n",
    "['Q2', 'Q3', 'Q4', 'Q5', 'Q8', 'Q9']\n",
    "```\n",
    "# 응답 설문 문항\n",
    "```\n",
    "question = ['Q2', 'Q3', 'Q4', 'Q5', 'Q6_1', 'Q6_2', 'Q6_3', 'Q6_4', 'Q6_5', 'Q6_6',\n",
    "       'Q6_7', 'Q6_8', 'Q6_9', 'Q6_10', 'Q6_11', 'Q6_12', 'Q7_1', 'Q7_2',\n",
    "       'Q7_3', 'Q7_4', 'Q7_5', 'Q7_6', 'Q7_7', 'Q8', 'Q9', 'Q10_1', 'Q10_2',\n",
    "       'Q10_3']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q2', 'Q3', 'Q4', 'Q5', 'Q8', 'Q9']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 설문 문항\n",
    "questions = [\n",
    "    'Q2', 'Q3', 'Q4', 'Q5', 'Q6_1', 'Q6_2', 'Q6_3', 'Q6_4', 'Q6_5', 'Q6_6', \n",
    "    'Q6_7', 'Q6_8', 'Q6_9', 'Q6_10', 'Q6_11', 'Q6_12', 'Q7_1', 'Q7_2',\n",
    "    'Q7_3', 'Q7_4', 'Q7_5', 'Q7_6', 'Q7_7', 'Q8', 'Q9', 'Q10_1', 'Q10_2',\n",
    "    'Q10_3'\n",
    "]\n",
    "\n",
    "qlst = []\n",
    "\n",
    "for question in questions:\n",
    "    if '_' not in question:\n",
    "        qlst.append(question)\n",
    "\n",
    "qlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q2', 'Q3', 'Q4', 'Q5', 'Q8', 'Q9']\n",
      "['Q2', 'Q3', 'Q4', 'Q5', 'Q8', 'Q9']\n"
     ]
    }
   ],
   "source": [
    "import  re\n",
    "\n",
    "# 응답 설문 문항\n",
    "questions = [\n",
    "    'Q2', 'Q3', 'Q4', 'Q5', 'Q6_1', 'Q6_2', 'Q6_3', 'Q6_4', 'Q6_5', 'Q6_6', \n",
    "    'Q6_7', 'Q6_8', 'Q6_9', 'Q6_10', 'Q6_11', 'Q6_12', 'Q7_1', 'Q7_2',\n",
    "    'Q7_3', 'Q7_4', 'Q7_5', 'Q7_6', 'Q7_7', 'Q8', 'Q9', 'Q10_1', 'Q10_2',\n",
    "    'Q10_3'\n",
    "]\n",
    "\n",
    "# 단순 문자 포함 방법\n",
    "\n",
    "qlst = []\n",
    "\n",
    "for question in questions:\n",
    "    if '_' not in question:\n",
    "        qlst.append(question)\n",
    "\n",
    "print(qlst)\n",
    "\n",
    "# 정규식 사용 방법\n",
    "\n",
    "import re\n",
    "\n",
    "qlst2 = []\n",
    "\n",
    "for question in questions:\n",
    "    if re.search(r'^Q\\d$', question):\n",
    "        qlst2.append(question)\n",
    "\n",
    "print(qlst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "한스 로슬링(Hans Rosling, 1948년 7월 27일 ~ 2017년 2월 7일)은 스웨덴의 의사이자 통계학자로 비영리 벤처 갭마인더 재단의 공동설립자이기도 합니다. 빅데이터를 가장 잘 활용하는 보건 통계학자로 알려져 있습니다. 베스트셀러 책인 \"팩트풀니스\" 저자이기도 합니다. 갭마인더 사이트에서는 연도별, 국가별 GDP와 기대수명 데이터를 제공하고 있는데, 대표적으로 파이썬 라이브러리 중 'seaborn'에서 제공되는 예제 데이터가 있습니다. 오늘은 이 데이터를 활용해 문제를 풀어보겠습니다. \n",
    "\n",
    "다음의 데이터는 연도, 국가별 기대수명을 나타내고 있는 데이터 입니다. 2011년 부터의 연도별, 국가별 평균 기대수명을 구해주세요. (2011년도 포함되게 구합니다.)\n",
    "\n",
    "[필수 조건] groupby 나 pivot_table을 활용합니다. groupby 로 구할 때 unstack()이라는 기능을 사용하여 아래와 같이 컬럼에 인덱스 값을 올려서 표기할 수 있습니다.\n",
    "만약 행에는 '연도'가, 열에 '국가'가 들어있고 수치 데이터의 결과값이 아래와 같다면, 출력형태는 조금 달라도 괜찮습니다.\n",
    "\n",
    "데이터는 다음의 방법으로 읽어옵니다.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/healthexp.csv\")\n",
    "df\n",
    "```\n",
    "\n",
    "🔽 출력 예시\n",
    "\n",
    "Year\tCanada\tFrance\tGermany\tGreat Britain\tJapan\tUSA\n",
    "2011\t81.4\t82.3\t80.5\t81.0\t82.7\t78.7\n",
    "2012\t81.6\t82.1\t80.6\t81.0\t83.2\t78.8\n",
    "2013\t81.7\t82.3\t80.6\t81.1\t83.4\t78.8\n",
    "2014\t81.8\t82.8\t81.2\t81.4\t83.7\t78.9\n",
    "2015\t81.9\t82.4\t80.7\t81.0\t83.9\t78.7\n",
    "2016\t82.0\t82.7\t81.0\t81.2\t84.1\t78.7\n",
    "2017\t81.9\t82.7\t81.1\t81.3\t84.2\t78.6\n",
    "2018\t82.0\t82.8\t81.0\t81.3\t84.3\t78.7\n",
    "2019\t82.2\t82.9\t81.3\t81.4\t84.4\t78.8\n",
    "2020\t81.7\t82.3\t81.1\t80.4\t84.7\t77.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 호출\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/healthexp.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 호출\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/healthexp.csv\")\n",
    "\n",
    "# 피벗 테이블 생성\n",
    "df_group = df.copy()\n",
    "\n",
    "df_group = df_group.groupby(['Year', 'Country'])['Life_Expectancy'].mean().unstack()\n",
    "\n",
    "df_group.sort_index(axis=0, ascending=True)\n",
    "\n",
    "print('--- groupby 사용 ---')\n",
    "\n",
    "print(df_group.loc[2011:])\n",
    "\n",
    "# 피벗 테이블 생성\n",
    "df_pivot = df.copy()\n",
    "\n",
    "df_pivot = df_pivot.pivot_table(\n",
    "    values = 'Life_Expectancy',\n",
    "    index = 'Year',\n",
    "    columns = 'Country',\n",
    "    aggfunc = 'mean'\n",
    ")\n",
    "\n",
    "df_pivot.sort_index(axis=0, ascending=True)\n",
    "\n",
    "print('--- pivot table 사용 ---')\n",
    "\n",
    "print(df_pivot.loc[2011:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "\n",
    "Jupyter notebook 은 문서와 코드를 함께 작성할 수 있다는 점이 장점입니다. Jupyter notebook 에서 지원하는 Markdown 문법을 사용하여, 이번 주에 배운 내용을 정리해 보세요!\n",
    "\n",
    "이번주 학습 내용은 다음 링크를 참고해주세요! [1주차 학습 내용] (스터디 전용 강좌 1주차 학습 안내 링크)\n",
    "1. 데이터 분석 환경 구성 : https://www.boostcourse.org/ds112/joinLectures/28140\n",
    "2. 데이터 분석 준비하기 : https://www.boostcourse.org/ds112/joinLectures/28138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas를 통한 파일 저장과 불러오기\n",
    "  * to_csv(\"파일명\", index=False) : csv 파일로 저장하기\n",
    "  * read_csv(\"파일명\") : csv 파일 불러오기\n",
    "  * shape를 통한 행과 열의 수 보기\n",
    "  * head, tail, sample 을 통한 일부 데이터 가져오기\n",
    "\n",
    "- DataFrame의 info(), describe() 등을 통한 요약과 기술통계 값 구하기\n",
    "  * info()\n",
    "  * describe()\n",
    "  * nunique()\n",
    "  * index\n",
    "  * columns\n",
    "  * values\n",
    "\n",
    "- Pandas의 DataFrame과 Series의 이해\n",
    "  * Series : 1차원 벡터구조\n",
    "  * DataFrame : 2차원 행렬구조\n",
    "\n",
    "- 색인하기\n",
    "  * [컬럼]\n",
    "  * loc[행]\n",
    "  * .loc[행, 열]\n",
    "  * .loc[조건식, 열]\n",
    "\n",
    "- DataFrame의 데이터 타입 이해하기\n",
    "  * 날짜 데이터의 변환\n",
    "\n",
    "- DataFrame 다루기\n",
    "  * 열(column) 인덱싱\n",
    "  * 행(index) 인덱싱\n",
    "  * 행, 열 인덱싱\n",
    "  * 정렬하기 : sort_values 사용하기\n",
    "  * 조건식 사용하기\n",
    "\n",
    "- 빈도수 구하기\n",
    "  * 한 개의 변수 : series.value_counts()\n",
    "  * 두 개의 변수 : pd.crosstab()\n",
    "\n",
    "- groupby 와 pivot_table\n",
    "  * 다양한 연산식의 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "\n",
    "앞으로 우리는 공공데이터포털에서 데이터를 다운로드 받아 과정을 진행할 예정입니다. 본격적인 학습 이전에! 데이터를 다루는 방법이 익숙해지도록 한번 더 연습해보고, 어떤 문제를 풀 수 있을지도 함께 고민해보아요!\n",
    "\n",
    "공공데이터포털에서 원하는 데이터를 다운로드 받아 경로를 설정하고, 주피터 노트북과 판다스를 통해 불러와 보세요!\n",
    "어떤 데이터를 사용해야할지 고민된다면 다음 링크의 데이터를 다운로드 받아도 좋습니다.\n",
    "\n",
    "이 때, 인코딩 오류가 발생한다면 encoding=\"cp949\" 옵션을 사용해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 참조 : http://data.seoul.go.kr/dataList/OA-12252/S/1/datasetView.do\n",
    "\n",
    "# 각 지하철 역별 승하차 인원 총계 취합 (Row : 지하철역, Col : 년월 )\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./서울시 지하철 호선별 역별 시간대별 승하차 인원 정보.csv\", encoding='cp949')\n",
    "\n",
    "df_pivot = df.copy()\n",
    "\n",
    "df_pivot['총 승차인원'] = 0\n",
    "\n",
    "df_pivot['총 하차인원'] = 0\n",
    "\n",
    "for index in list(df_pivot):\n",
    "    if index.endswith('승차인원'):\n",
    "        df_pivot['총 승차인원'] += df_pivot[index]\n",
    "    if index.endswith('하차인원'):\n",
    "        df_pivot['총 하차인원'] += df_pivot[index]\n",
    "\n",
    "# 피벗 테이블 생성 - 승차 / 하차 이렇게 나뉠 것이다.\n",
    "df_pivot = df_pivot.pivot_table(\n",
    "    values = ['총 승차인원', '총 하차인원'],\n",
    "    index = '지하철역',\n",
    "    columns = '사용월',\n",
    "    aggfunc = 'sum'\n",
    ")\n",
    "\n",
    "df_pivot.to_excel('output.xlsx', sheet_name='승하차_취합')\n",
    "\n",
    "print(df_pivot)\n",
    "\n",
    "# 유의 사항 : 결측값이 나올 수도 있다. 사유는 아래와 같다.\n",
    "# - 일부 지하철 역에 대해 개통이 이뤄지지 않았을 경우 (ex. 신림선 - 서울지방병무청역은 2022년 5월 이후 개통되어 이전 데이터는 NaN 이 나옴.)\n",
    "# - 일부 지하철 역에 대해 측정이 이뤄지지 않았을 경우\n",
    "# - 인구 측정 중 천재지변으로 인한 작업 중단이 발생한 경우 등"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
